---
title: "8.3_bootstrapping"
author: "Wenshan Qu (wq2160)"
date: "11/23/2021"
output: html_document
---

```{r}
library(tidyverse)
library(p8105.datasets)
library(modelr)

set.seed(1)


knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

Simulate a dataset

```{r}
n_samp = 250

sim_df_const = 
  tibble(
    x = rnorm(n_samp, 1, 1),
    error = rnorm(n_samp, 0, 1),
    y = 2 + 3 * x + error
  )

sim_df_nonconst = sim_df_const %>% 
  mutate(
  error = error * .75 * x,
  y = 2 + 3 * x + error
)
```

Make a plot

```{r}
sim_df_nonconst %>% 
  ggplot(aes(x = x, y = y)) +
  geom_point()
```

```{r}
sim_df_nonconst %>% 
  lm(y ~ x, data = .) %>% 
  broom::tidy()
```

good estimitae, but bad std.error...

_We wanna get the regression line of the `sim_df_nonconst`, but this is not a constant dataset, while the `slope` may be nice... but we will get terrible `sd` and `ci` because the `lm()` assume our data is constant. That why we use the bootstrap to **get the distribution of parameters**_

## Let's try to use the bootstrap for inference

```{r}
bootstrap_sample = 
  sim_df_nonconst %>% 
  sample_frac(size = 1, replace = TRUE) %>% 
  arrange(x)

lm(y ~ x, data = bootstrap_sample)
```

## Let's write a function

```{r}
boot_sample = function(df) {
  
  sample_frac(df, size = 1, replace = TRUE)
  
}
```

Now we will make a tibble to keep track of everything.

```{r}
boot_strap_df = 
  tibble(
    strap_number = 1:1000,
    strap_sample = rerun(1000, boot_sample(sim_df_nonconst)) ## rerun 1000 times
  )


boot_strap_df
```

From here... things are kinda teh same as "always"

```{r}
bootstrap_results = 
  boot_strap_df %>% 
  mutate(
    models = map(.x = strap_sample, ~lm(y ~ x, data = .x)),
    results = map(models, broom::tidy)
  ) %>% 
  select(strap_number, results) %>% 
  unnest(results)

bootstrap_results %>% 
  ggplot(aes(x = estimate)) +
  geom_histogram() +
  facet_grid(~term, scales = "free")



## Let's compare these two methods about how precise the sd is given
## Method 1, simply use lm()...
lm(y ~ x, data = sim_df_const) %>% 
  
  broom::tidy()
## Method 2, repeat sampling and the mean dist...
bootstrap_results %>% 
  group_by(term) %>% 
  summarize(
    se = sd(estimate)
  )
```


## Alternative way: Use `modelr`, much easier!

```{r}
sim_df_nonconst %>% 
  bootstrap(n = 1000, id = "strap_number") %>% 
  mutate(
    model = map(.x = strap, ~lm(y ~ x, data = .x)),
    results = map(model, broom::tidy)
  )
```


## Airbnb data

```{r}
data("nyc_airbnb")

nyc_airbnb = 
   nyc_airbnb %>% 
  mutate(stars = review_scores_location / 2) %>% 
  rename(
    borough = neighbourhood_group
  ) %>% 
  filter(borough != "Staten Island") %>% 
  select(price, stars, borough, room_type)
```


First we could make a plot..
But the problem is that, there is a maybe? linear relationship, but so many outliers, we may not get a nice estimation using lm().

```{r}
nyc_airbnb %>% 
  ggplot(aes(x = stars, y = price)) +
  geom_point()
```

So bootsrap

```{r}
airbnb_bootstrap_results = 
  nyc_airbnb %>% 
  filter(borough == "Manhattan") %>% 
  bootstrap(n = 100, id = "strap_number") %>% 
  mutate(
    models = map(.x = strap, ~lm(price ~ stars, data = .x)),
    results = map(models, broom::tidy)
  ) %>% 
  select(strap_number, results) %>% 
  unnest(results)

airbnb_bootstrap_results

## Compare 1
ggp_star_estimate =   
  airbnb_bootstrap_results %>% 
  filter(term == "stars") %>% ## that is slope
  ggplot(aes(estimate)) +
  geom_density()

## Compare 2 (origin)
ggp_scatter = 
  nyc_airbnb %>% 
  filter(borough == "Manhattan") %>% 
  ggplot(aes(x = stars, y = price)) +
  geom_point()

library(patchwork)
ggp_star_estimate + ggp_scatter
```

Not quite a normal dist... seems like more points "skewed" to left?

